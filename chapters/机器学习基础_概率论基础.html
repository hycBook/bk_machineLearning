
<!DOCTYPE HTML>
<html lang="zh-hans" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>机器学习基础_概率论基础 · 机器学习相关学习记录</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        <meta name="author" content="narutohyc">
        
        
    
    
    <link rel="stylesheet" href="../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-splitter/splitter.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-expandable-chapters-small/expandable-chapters-small.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-anchors/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-donate/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-anchor-navigation-ex/style/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-mermaid-gb3/mermaid/mermaid.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-tbfed-pagefooter/footer.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    


    

        
    
    
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="机器学习基础_线性代数基础.html" />
    
    
    <link rel="prev" href="机器学习基础_距离.html" />
    

    
        <link rel="shortcut icon" href='../https:/upload-images.jianshu.io/upload_images/15675864-5e5ba668035853d8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240' type="image/x-icon">
    
    
        <link rel="bookmark" href='../https:/upload-images.jianshu.io/upload_images/15675864-5e5ba668035853d8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240' type="image/x-icon">
    
    
        <link rel="apple-touch-icon" href='../https:/upload-images.jianshu.io/upload_images/15675864-5e5ba668035853d8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240'>
    
    
        
        <link rel="apple-touch-icon" sizes="120x120" href="../https:/upload-images.jianshu.io/upload_images/15675864-5e5ba668035853d8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
        
        <link rel="apple-touch-icon" sizes="180x180" href="../https:/upload-images.jianshu.io/upload_images/15675864-5e5ba668035853d8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
        
    

    <style>
    @media only screen and (max-width: 640px) {
        .book-header .hidden-mobile {
            display: none;
        }
    }
    </style>
    <script>
        window["gitbook-plugin-github-buttons"] = {"buttons":[{"user":"narutohyc","repo":"bk_machineLearning","type":"star","size":"small","count":true}]};
    </script>

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="输入并搜索" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    
    
        
        <li>
            <a href="https://github.com/narutohyc" target="_blank" class="custom-link">我的狗窝</a>
        </li>
    
    

    
    <li class="divider"></li>
    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="../">
            
                <a href="../">
            
                    
                        <b>1.1.</b>
                    
                    Introduction
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="机器学习基础.html">
            
                <a href="机器学习基础.html">
            
                    
                        <b>1.2.</b>
                    
                    机器学习基础
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.1" data-path="机器学习基础_距离.html">
            
                <a href="机器学习基础_距离.html">
            
                    
                        <b>1.2.1.</b>
                    
                    机器学习基础_距离
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.2.2" data-path="机器学习基础_概率论基础.html">
            
                <a href="机器学习基础_概率论基础.html">
            
                    
                        <b>1.2.2.</b>
                    
                    机器学习基础_概率论基础
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3" data-path="机器学习基础_线性代数基础.html">
            
                <a href="机器学习基础_线性代数基础.html">
            
                    
                        <b>1.2.3.</b>
                    
                    机器学习基础_线性代数基础
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.4" data-path="机器学习基础_微积分基础.html">
            
                <a href="机器学习基础_微积分基础.html">
            
                    
                        <b>1.2.4.</b>
                    
                    机器学习基础_微积分基础
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.5" data-path="机器学习基础_最优化理论.html">
            
                <a href="机器学习基础_最优化理论.html">
            
                    
                        <b>1.2.5.</b>
                    
                    机器学习基础_最优化理论
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.6" data-path="机器学习基础_损失函数.html">
            
                <a href="机器学习基础_损失函数.html">
            
                    
                        <b>1.2.6.</b>
                    
                    机器学习基础_损失函数
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="特征工程.md">
            
                <span>
            
                    
                        <b>1.3.</b>
                    
                    特征工程
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.1" data-path="特征工程_归一化.html">
            
                <a href="特征工程_归一化.html">
            
                    
                        <b>1.3.1.</b>
                    
                    特征工程_归一化
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2" data-path="特征工程_编码.html">
            
                <a href="特征工程_编码.html">
            
                    
                        <b>1.3.2.</b>
                    
                    特征工程_编码
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.3" data-path="特征工程_特征组合.html">
            
                <a href="特征工程_特征组合.html">
            
                    
                        <b>1.3.3.</b>
                    
                    特征工程_特征组合
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.4" data-path="特征工程_特征选择.html">
            
                <a href="特征工程_特征选择.html">
            
                    
                        <b>1.3.4.</b>
                    
                    特征工程_特征选择
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.5" data-path="特征工程_文本表示模型.html">
            
                <a href="特征工程_文本表示模型.html">
            
                    
                        <b>1.3.5.</b>
                    
                    特征工程_文本表示模型
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.6" data-path="特征工程_图像增强.html">
            
                <a href="特征工程_图像增强.html">
            
                    
                        <b>1.3.6.</b>
                    
                    特征工程_图像增强
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.4" data-path="模型评估.md">
            
                <span>
            
                    
                        <b>1.4.</b>
                    
                    模型评估
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.4.1" data-path="模型评估_评估指标.html">
            
                <a href="模型评估_评估指标.html">
            
                    
                        <b>1.4.1.</b>
                    
                    模型评估_评估指标
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.2" data-path="模型评估_AB测试.html">
            
                <a href="模型评估_AB测试.html">
            
                    
                        <b>1.4.2.</b>
                    
                    模型评估_AB测试
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.3" data-path="模型评估_过拟合和欠拟合.html">
            
                <a href="模型评估_过拟合和欠拟合.html">
            
                    
                        <b>1.4.3.</b>
                    
                    模型评估_过拟合和欠拟合
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.4" data-path="模型评估_超参数选择.html">
            
                <a href="模型评估_超参数选择.html">
            
                    
                        <b>1.4.4.</b>
                    
                    模型评估_超参数选择
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.5" data-path="模型评估_模型评估方法.html">
            
                <a href="模型评估_模型评估方法.html">
            
                    
                        <b>1.4.5.</b>
                    
                    模型评估_模型评估方法
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.5" data-path="降维.md">
            
                <span>
            
                    
                        <b>1.5.</b>
                    
                    降维
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.1" data-path="降维_PCA主成分分析.html">
            
                <a href="降维_PCA主成分分析.html">
            
                    
                        <b>1.5.1.</b>
                    
                    降维_PCA主成分分析
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.2" data-path="降维_LDA线性判别分析.html">
            
                <a href="降维_LDA线性判别分析.html">
            
                    
                        <b>1.5.2.</b>
                    
                    降维_LDA线性判别分析
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.6" data-path="监督学习.md">
            
                <span>
            
                    
                        <b>1.6.</b>
                    
                    监督学习
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.1" data-path="监督学习_朴素贝叶斯分类.html">
            
                <a href="监督学习_朴素贝叶斯分类.html">
            
                    
                        <b>1.6.1.</b>
                    
                    监督学习_朴素贝叶斯分类
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2" data-path="监督学习_决策树.html">
            
                <a href="监督学习_决策树.html">
            
                    
                        <b>1.6.2.</b>
                    
                    监督学习_决策树
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.3" data-path="监督学习_K近邻法.html">
            
                <a href="监督学习_K近邻法.html">
            
                    
                        <b>1.6.3.</b>
                    
                    监督学习_K近邻法
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.4" data-path="监督学习_支持向量机.html">
            
                <a href="监督学习_支持向量机.html">
            
                    
                        <b>1.6.4.</b>
                    
                    监督学习_支持向量机
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.7" data-path="非监督学习.html">
            
                <a href="非监督学习.html">
            
                    
                        <b>1.7.</b>
                    
                    非监督学习
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.7.1" data-path="非监督学习_K均值.html">
            
                <a href="非监督学习_K均值.html">
            
                    
                        <b>1.7.1.</b>
                    
                    非监督学习_K均值
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.2" data-path="非监督学习_Mean Shift均值漂移聚类.html">
            
                <a href="非监督学习_Mean Shift均值漂移聚类.html">
            
                    
                        <b>1.7.2.</b>
                    
                    非监督学习_Mean Shift均值漂移聚类
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.3" data-path="非监督学习_DBSCAN基于密度的聚类方法.html">
            
                <a href="非监督学习_DBSCAN基于密度的聚类方法.html">
            
                    
                        <b>1.7.3.</b>
                    
                    非监督学习_DBSCAN基于密度的聚类方法
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.4" data-path="非监督学习_Hierarchical Clustering层次聚类.html">
            
                <a href="非监督学习_Hierarchical Clustering层次聚类.html">
            
                    
                        <b>1.7.4.</b>
                    
                    非监督学习_Hierarchical Clustering层次聚类
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.5" data-path="非监督学习_Spectral Clustering谱聚类.html">
            
                <a href="非监督学习_Spectral Clustering谱聚类.html">
            
                    
                        <b>1.7.5.</b>
                    
                    非监督学习_Spectral Clustering谱聚类
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.8" data-path="半监督学习.html">
            
                <a href="半监督学习.html">
            
                    
                        <b>1.8.</b>
                    
                    半监督学习
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.9" data-path="集成学习.html">
            
                <a href="集成学习.html">
            
                    
                        <b>1.9.</b>
                    
                    集成学习
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10" data-path="强化学习.html">
            
                <a href="强化学习.html">
            
                    
                        <b>1.10.</b>
                    
                    强化学习
            
                </a>
            

            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            本书使用 GitBook 发布
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >机器学习基础_概率论基础</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <div id="anchor-navigation-ex-navbar"><i class="fa fa-navicon"></i><ul><li><span class="title-icon "></span><a href="#&#x6982;&#x7387;&#x8BBA;&#x57FA;&#x7840;"><b></b>&#x6982;&#x7387;&#x8BBA;&#x57FA;&#x7840;</a></li><li><span class="title-icon "></span><a href="#&#x6982;&#x7387;&#x7A7A;&#x95F4;"><b></b>&#x6982;&#x7387;&#x7A7A;&#x95F4;</a></li></ul></div><a href="#&#x6982;&#x7387;&#x8BBA;&#x57FA;&#x7840;" id="anchorNavigationExGoTop"><i class="fa fa-arrow-up"></i></a><p><img src="https://upload-images.jianshu.io/upload_images/15675864-e39212ac990782cf.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="&#x5F02;&#x4E16;&#x754C;.png"></p>
<p>[TOC]</p>
<h1 id="&#x6982;&#x7387;&#x8BBA;&#x57FA;&#x7840;"><a name="&#x6982;&#x7387;&#x8BBA;&#x57FA;&#x7840;" class="anchor-navigation-ex-anchor" href="#&#x6982;&#x7387;&#x8BBA;&#x57FA;&#x7840;"><i class="fa fa-link" aria-hidden="true"></i></a><a name="&#x6982;&#x7387;&#x8BBA;&#x57FA;&#x7840;" class="plugin-anchor" href="#&#x6982;&#x7387;&#x8BBA;&#x57FA;&#x7840;"><i class="fa fa-link" aria-hidden="true"></i></a>&#x6982;&#x7387;&#x8BBA;&#x57FA;&#x7840;</h1>
<h1 id="&#x6982;&#x7387;&#x7A7A;&#x95F4;"><a name="&#x6982;&#x7387;&#x7A7A;&#x95F4;" class="anchor-navigation-ex-anchor" href="#&#x6982;&#x7387;&#x7A7A;&#x95F4;"><i class="fa fa-link" aria-hidden="true"></i></a><a name="&#x6982;&#x7387;&#x7A7A;&#x95F4;" class="plugin-anchor" href="#&#x6982;&#x7387;&#x7A7A;&#x95F4;"><i class="fa fa-link" aria-hidden="true"></i></a>&#x6982;&#x7387;&#x7A7A;&#x95F4;</h1>
<blockquote>
<p>&#x8BF4;&#x5230;&#x6982;&#x7387;&#xFF0C;&#x901A;&#x5E38;&#x662F;&#x6307;&#x4E00;&#x4E2A;&#x5177;&#x6709;&#x4E0D;&#x786E;&#x5B9A;&#x6027;&#x7684;<code>event</code>&#x53D1;&#x751F;&#x7684;&#x53EF;&#x80FD;&#x6027;&#xFF0C;&#x4F8B;&#x5982;&#xFF0C;&#x4E0B;&#x5468;&#x4E8C;&#x4E0B;&#x96E8;&#x7684;&#x6982;&#x7387;&#x3002;</p>
<p>&#x56E0;&#x6B64;&#xFF0C;&#x4E3A;&#x4E86;&#x6B63;&#x5F0F;&#x5730;&#x8BA8;&#x8BBA;&#x6982;&#x7387;&#x8BBA;&#xFF0C;&#x6211;&#x4EEC;&#x9996;&#x5148;&#x8981;&#x660E;&#x786E;&#x4EC0;&#x4E48;&#x662F;&#x53EF;&#x80FD;&#x4E8B;&#x4EF6;&#x3002;
&#x6B63;&#x89C4;&#x8BF4;&#x6765;&#xFF0C;&#x4E00;&#x4E2A;<code>probability space</code>&#x662F;&#x7531;&#x4E09;&#x5143;&#x7EC4;<script type="math/tex; ">(\Omega,F,P)</script>&#x5B9A;&#x4E49;&#xFF1A;</p>
<p>&#x200B;    -<script type="math/tex; ">\Omega</script>&#x4E3A;&#x6837;&#x672C;&#x7A7A;&#x95F4; </p>
<p>&#x200B;    -<script type="math/tex; ">F \subseteq 2^\Omega</script>(0&#x7684;&#x5E42;&#x96C6;)&#x4E3A;(&#x53EF;&#x5EA6;&#x91CF;&#x7684;)&#x4E8B;&#x4EF6;&#x7A7A;&#x95F4; </p>
<p>&#x200B;    -<script type="math/tex; ">P</script>&#x4E3A;&#x5C06;&#x4E8B;&#x4EF6;<script type="math/tex; ">E \in F</script>&#x6620;&#x5C04;&#x5230;<script type="math/tex; ">0~1</script>&#x771F;&#x503C;&#x533A;&#x95F4;&#x7684;&#x6982;&#x7387;&#x5EA6;&#x91CF;(&#x6982;&#x7387;&#x5206;&#x5E03;)&#xFF0C;&#x53EF;&#x4EE5;&#x5C06;<script type="math/tex; ">P</script>&#x770B;&#x4F5C;<strong>&#x6982;&#x7387;&#x51FD;&#x6570;</strong></p>
<p>&#x6CE8;&#xFF1A;<script type="math/tex; ">\Omega</script>&#x7684;&#x5E42;&#x96C6;<script type="math/tex; ">2^\Omega</script>--&#x662F;<script type="math/tex; "> \Omega </script>&#x7684;&#x6240;&#x6709;&#x5B50;&#x96C6;&#x7684;&#x96C6;&#x5408;&#xFF0C;&#x7B26;&#x53F7;&#xFF1A;<script type="math/tex; ">P(\Omega)=\{ U|U \subseteq \Omega\}</script>&#xFF0C;<script type="math/tex; ">| \Omega |=n</script>&#x4E2A;&#x5143;&#x7D20;&#xFF0C;<script type="math/tex; ">|P( \Omega)|=2^n</script>&#x4E2A;&#x5143;&#x7D20;&#x3002;</p>
<p>&#x5047;&#x8BBE;&#x7ED9;&#x5B9A;&#x6837;&#x672C;&#x7A7A;&#x95F4;<script type="math/tex; "> \Omega </script>&#xFF0C;&#x5219;&#x5BF9;&#x4E8E;&#x4E8B;&#x4EF6;&#x7A7A;&#x95F4;<script type="math/tex; ">F</script>&#x6765;&#x8BF4;&#xFF1A;</p>
<p>&#x200B;    -<script type="math/tex; ">F</script>&#x5305;&#x542B;<script type="math/tex; "> \Omega </script>&#x672C;&#x8EAB;&#x548C;<script type="math/tex; ">\emptyset</script></p>
<p>&#x200B;    -<script type="math/tex; ">F</script>&#x5BF9;&#x4E8E;&#x5E76;&#x96C6;&#x95ED;&#x5408;&#xFF0C;&#x4F8B;&#x5982;&#xFF1A;&#x5982;&#x679C;<script type="math/tex; ">\alpha , \beta \in F</script>&#xFF0C;&#x5219;<script type="math/tex; ">\alpha \cup \beta \in F</script> </p>
<p>&#x200B;    -<script type="math/tex; ">F</script>&#x5BF9;&#x4E8E;&#x8865;&#x96C6;&#x95ED;&#x5408;&#xFF0C;&#x4F8B;&#x5982;&#xFF1A;&#x5982;&#x679C;<script type="math/tex; ">\alpha \in F</script>&#xFF0C;&#x5219;<script type="math/tex; ">(\Omega / \alpha) \in F</script> </p>
<p><strong>Example1</strong>: &#x5047;&#x5982;&#x6211;&#x4EEC;&#x6295;&#x63B7;&#x4E00;&#x4E2A;&#xFF08;6&#x9762;&#xFF09;&#x9AB0;&#x5B50;&#xFF0C;&#x90A3;&#x4E48;&#x53EF;&#x80FD;&#x7684;&#x6837;&#x672C;&#x7A7A;&#x95F4;<script type="math/tex; ">\Omega =\{ 1,2,3,4,5,6\}</script>&#x3002;</p>
<p>&#x6211;&#x4EEC;&#x53EF;&#x80FD;&#x611F;&#x5174;&#x8DA3;&#x7684;&#x4E8B;&#x4EF6;&#x662F;&#x9AB0;&#x5B50;&#x70B9;&#x6570;&#x662F;&#x5947;&#x6570;&#x8FD8;&#x662F;&#x5076;&#x6570;&#xFF0C;</p>
<p>&#x200B;    &#x90A3;&#x4E48;&#x8FD9;&#x79CD;&#x60C5;&#x51B5;&#x4E0B;&#x4E8B;&#x4EF6;&#x7A7A;&#x95F4;&#x5C31;&#x662F;<script type="math/tex; ">F=\{ \emptyset, \{1,3,5\}, \{2,4,6\} \}</script>.
&#x200B;    &#x53EF;&#x4EE5;&#x770B;&#x5230;&#x6837;&#x672C;&#x7A7A;&#x95F4;<script type="math/tex; "> \Omega </script>&#x4E3A;&#x6709;&#x9650;&#x96C6;&#x65F6;&#xFF0C;&#x5C31;&#x50CF;&#x4E0A;&#x4E00;&#x4E2A;&#x4F8B;&#x5B50;&#xFF0C;&#x6211;&#x4EEC;&#x901A;&#x5E38;&#x4EE4;&#x4E8B;&#x4EF6;&#x7A7A;&#x95F4;<script type="math/tex; ">F</script>&#x4E3A;<script type="math/tex; ">2^{\Omega}</script>&#x3002;&#x8FD9;&#x79CD;&#x7B56;&#x7565;&#x5E76;&#x4E0D;&#x5B8C;&#x5168;&#x901A;&#x7528;&#xFF0C;&#x4F46;&#x662F;&#x5728;&#x5B9E;&#x9645;&#x4F7F;&#x7528;&#x4E2D;&#x901A;&#x5E38;&#x662F;&#x6709;&#x6548;&#x7684;&#x3002;</p>
<p>&#x200B;    &#x7136;&#x800C;&#xFF0C;&#x5F53;&#x6837;&#x672C;&#x7A7A;&#x95F4;&#x4E3A;&#x65E0;&#x9650;&#x96C6;&#x65F6;&#xFF0C;&#x6211;&#x4EEC;&#x9700;&#x8981;&#x4ED4;&#x7EC6;&#x5B9A;&#x4E49;&#x4E8B;&#x4EF6;&#x7A7A;&#x95F4;&#x3002;&#x7ED9;&#x5B9A;&#x4E00;&#x4E2A;&#x4E8B;&#x4EF6;&#x7A7A;&#x95F4;<script type="math/tex; ">F</script>&#xFF0C;&#x6982;&#x7387;&#x51FD;&#x6570;<script type="math/tex; ">P</script>&#x9700;&#x8981;&#x6EE1;&#x8DB3;&#x51E0;&#x4E2A;&#x516C;&#x7406;&#xFF1A; </p>
<p>&#x200B;    -(&#x975E;&#x8D1F;)&#x5BF9;&#x4E8E;&#x6240;&#x6709;<script type="math/tex; ">\alpha</script>&#xFF0C;<script type="math/tex; ">P(a）\ge 0</script> </p>
<p>&#x200B;    -P(F)=1&#xFF0C;&#x4E8B;&#x4EF6;&#x7A7A;&#x95F4;&#x7684;&#x6982;&#x7387;&#x503C;&#x4E3A;1 </p>
<p>&#x200B;    -(&#x4E92;&#x65A5;&#x4E8B;&#x4EF6;&#x7684;&#x52A0;&#x6CD5;&#x6CD5;&#x5219;)&#x5BF9;&#x4E8E;&#x6240;&#x6709;<script type="math/tex; ">\alpha,\beta \in F</script>&#x548C;<script type="math/tex; ">\alpha \cap \beta = \emptyset</script>&#xFF0C;<script type="math/tex; ">P(\alpha \cup \beta)=P(\alpha)+P(\beta)</script></p>
<p><strong>Example2</strong>: &#x56DE;&#x5230;&#x63B7;&#x9AB0;&#x5B50;&#x7684;&#x4F8B;&#x5B50;&#xFF0C;&#x5047;&#x8BBE;&#x4E8B;&#x4EF6;&#x7A7A;&#x95F4;<script type="math/tex; ">F</script>&#x4E3A;<script type="math/tex; ">2^\Omega</script>&#xFF0C;&#x8FDB;&#x4E00;&#x6B65;&#x5730;&#xFF0C;&#x5B9A;&#x4E49;<script type="math/tex; ">F</script>&#x4E0A;&#x7684;&#x6982;&#x7387;&#x51FD;&#x6570;<script type="math/tex; ">P</script>&#x4E3A;&#xFF1A;
<script type="math/tex; ">$$
>P(\{1 \})=P(\{2 \})=...=P(\{6 \})=\frac{1}{6}
></script><script type="math/tex; mode=display">
>​	那么这种概率分布</script>P<script type="math/tex; ">可以完整定义任意给出事件的发生概率(通过可加性公理)。
>
>​	例如，投掷点数为偶数的概率为： </script>P{2,4,6}=P{2}+P{4}+P{6}=\frac{1}{6}+\frac{1}{6}+\frac{1}{6}=\frac{1}{62}<script type="math/tex; mode=display">
>
>​	因为任意事件(此处指样本空间内的投掷出各点数)之间都没有交集

# 随机变量

>随机变量在概率论中扮演着一个重要角色。
>
>最重要的一个事实是，随机变量并不是变量，它们实际上是将(样本空间中的)结果映射到真值的函数。
>
>我们通常用一个大写字母来表示随机变量。
>**Example3**: 还是以掷骰子为例，
>
>​	</script>X<script type="math/tex; ">为取决于投掷结果的随机变量，</script>X<script type="math/tex; ">的一个自然选择是将 </script>i<script type="math/tex; "> 映射到值 </script>i<script type="math/tex; ">。
>
>​	例如，将事件“投掷1点“映射到值1。我们也可以选择一些特别的映射，例如，我们有一个随机变量</script>Y<script type="math/tex; ">--将所有的结果映射到0，这就是一个很无聊的函数。或者随机变量</script>Z<script type="math/tex; ">--当 </script>i<script type="math/tex; "> 为奇数时，将结果映射到</script>2^i<script type="math/tex; ">；当 </script>i<script type="math/tex; "> 为偶数时，将结果 </script>i<script type="math/tex; "> 映射到 </script>i<script type="math/tex; ">。
>
>`从某种意义上说，随机变量可以将事件空间的形式概念抽象出来，通过定义随机变量来采集相关事件。`
>
>举个例子，考虑**Example1**中投掷点数为奇/偶的事件空间。
>
>我们其实可以定义一个随机变量，当结果 </script>i<script type="math/tex; "> 为奇数时取值为1，否则随机变量取值为0。
>
>这种二元算计变量在实际中非常常见，通常以指示变量为人所知，它是因用于指示某一特定事件是否发生而得名。
>
>所以为什么我们要引进事件空间？就是因为当一个人在学习概率论(更严格来说)通过计量理论来学习时，样本空间和事件空间的区别非常重要。
>
>​    随机变量让我们能提供一种对于概率论的更加统一的处理方式。取值为</script>a<script type="math/tex; ">的随机变量</script>X<script type="math/tex; ">的概率可以记为： </script>P(X=a)<script type="math/tex; ">或</script>P<em>X(a)<script type="math/tex; mode=display">
>
>

# 概率分布、联合分布和边缘分布

>变量的分布，正式来说，它是指一个随机变量取某一特定值的概率，
>
>**Example4**: 假设在投掷一个骰子的样本空间</script>\Omega<script type="math/tex; ">上定义一个随机变量</script>X<script type="math/tex; ">，如果骰子是均匀的，则</script>X<script type="math/tex; ">的分布为：</script>P_x(1)=P_x(2)=...=P_x(6)=\frac{1}{6}<script type="math/tex; ">。
>
>​    注意，尽管这个例子和**Example2**类似，但是它们有着不同的语义。
>
>​	**Example2**中定义的概率分布是对于事件而言，而这个例子中是随机变量的概率分布。
>​    我们用</script>P(X)<script type="math/tex; ">来表示随机变量</script>X<script type="math/tex; ">的概率分布。
>有时候，我们会同时讨论大于一个变量的概率分布，这种概率分布称为`联合分布`，因为此事的概率是由所涉及到的所有变量共同决定的。
>**Example5**: 在投掷一个骰子的样本空间上定义一个随机变量</script>X<script type="math/tex; ">。
>
>定义一个指示变量</script>Y<script type="math/tex; ">，当抛硬币结果为正面朝上时取1，反面朝上时取 0。
>
>假设骰子和硬币都是均匀的，则</script>X<script type="math/tex; ">和</script>Y<script type="math/tex; ">的联合分布如下： 
>
>| </script>P<script type="math/tex; ">   | </script>X=1<script type="math/tex; ">          | </script>X=2<script type="math/tex; ">          | </script>X=3<script type="math/tex; ">          | </script>X=4<script type="math/tex; ">          | </script>X=5 <script type="math/tex; ">         | </script>X=6<script type="math/tex; ">          |
>| ----- | -------------- | -------------- | -------------- | -------------- | -------------- | -------------- |
>| </script>Y=0<script type="math/tex; "> | </script>\frac{1}{12}<script type="math/tex; "> | </script>\frac{1}{12}<script type="math/tex; "> | </script>\frac{1}{12}<script type="math/tex; "> | </script>\frac{1}{12}<script type="math/tex; "> | </script>\frac{1}{12}<script type="math/tex; "> | </script>\frac{1}{12}<script type="math/tex; "> |
>| </script>Y=1<script type="math/tex; "> | </script>\frac{1}{12}<script type="math/tex; "> | </script>\frac{1}{12}<script type="math/tex; "> | </script>\frac{1}{12}<script type="math/tex; "> | </script>\frac{1}{12}<script type="math/tex; "> | </script>\frac{1}{12}<script type="math/tex; "> | </script>\frac{1}{12}<script type="math/tex; "> |
>
>像前面一样，我们可以用</script>P(X=a,Y=b)<script type="math/tex; ">或</script>P</em>{x,y}(a,b)<script type="math/tex; ">来表示</script>X<script type="math/tex; ">取值为</script>a<script type="math/tex; ">且</script>Y<script type="math/tex; ">取值为</script>b<script type="math/tex; ">时的概率。
>
>用</script>P(X,Y)<script type="math/tex; ">来表示它们的联合分布。
>
>
>
>假定有一个随机变量</script>X<script type="math/tex; ">和</script>Y<script type="math/tex; ">的联合分布，我们就能讨论</script>X<script type="math/tex; ">或</script>Y<script type="math/tex; ">的边缘分布。
>
>`边缘分布`是指一个随机变量对于其自身的概率分布。
>
>为了得到 一个随机变量的边缘分布，我们将该分布中的所有其它变量相加，准确来说，就是： 
></script><script type="math/tex; mode=display">
>P(X)=\sum_{b \in Val(Y)}{P（X,Y= b）}
></script><script type="math/tex; mode=display">
>之所以取名为边缘分布，是因为如果我们将一个联合分布的一列(或一行)的输入相加，将结果写在它的最后(也就是边缘)，那么该结果就是这个随机变量取该值时的概率。
>
>当然，这种思路仅在联合分布涉及两个变量时有帮助。
>
>

# 条件分布

>条件分布为概率论中用于探讨不确定性的关键工具之一。
>
>它明确了在另一随机变量已知的情况下（或者更通俗来说，当已知某事件为真 时）的某一随机变量的分布。
>    正式地，给定</script>Y=b<script type="math/tex; ">时，</script>X=a<script type="math/tex; ">的条件概率定义为：
></script><script type="math/tex; mode=display">
>P(X=a|Y=b)=\frac{P(X=a,Y=b)}{P(Y=b)}
></script><script type="math/tex; mode=display">
>注意，当</script>Y=b<script type="math/tex; ">的概率为0时，上式不成立。
>**Example6**: 假设我们已知一个骰子投出的点数为奇数，想要知道投出的点数为"1"的概率。
>
>令</script>X<script type="math/tex; ">为代表点数的随机变量，</script>Y<script type="math/tex; ">为指示变量，当点数为奇数时取值为1，那么我们期望的概率可以写为： 
></script><script type="math/tex; mode=display">
>P(X=1|Y=1)=\frac{P(X=1,Y=1)}{P(Y=1)}=\frac{\frac{1}{6}}{\frac{1}{2}}=\frac{1}{3}
></script><script type="math/tex; mode=display">
>条件概率的思想可以自然地扩展到一个随机变量的分布是以多个变量为条件时，即：
></script><script type="math/tex; mode=display">
>P(X=a|Y=b,Z=c)=\frac{P(X=a,Y=b,Z=c)}{P(Y=b,Z=c)}
></script><script type="math/tex; mode=display">
>我们用</script>P(X|Y = b)<script type="math/tex; ">来表示当</script>Y=b<script type="math/tex; ">时随机变量</script>X<script type="math/tex; ">的分布，也可以用</script>P(XIY)<script type="math/tex; ">来表示</script>X<script type="math/tex; ">的一系列分布，其中每一个都对应不同的</script>Y<script type="math/tex; ">可以取的值。
>
>

# 条件独立

>在概率论中，独立性是指随机变量的分布不因知道其它随机变量的值而改变。
>
>​	在机器学习中，我们通常都会对数据做这样的假设。例如，我们会假设训练样本是从某一底层空间独立提取；并且假设样例的标签独立于样例</script>j(i \neq j)<script type="math/tex; ">的特性。
>​	从数学角度来说，随机变量</script>X<script type="math/tex; ">独立于</script>Y<script type="math/tex; ">，当</script>P(X)=P(X|Y)<script type="math/tex; mode=display">
>
>(注意，上式没有标明</script>X<script type="math/tex; ">，</script>Y<script type="math/tex; ">的取值，也就是说该公式对任意</script>X<script type="math/tex; ">，</script>Y<script type="math/tex; ">可能的取值均成立)
>
>​	利用等式(2)，很容易可以证明如果</script>X<script type="math/tex; ">对</script>Y<script type="math/tex; ">独立，那么</script>Y<script type="math/tex; ">也独立于</script>X<script type="math/tex; ">。当</script>X<script type="math/tex; ">和</script>Y<script type="math/tex; ">相互独立时，记为</script>X \bot Y<script type="math/tex; ">。
>
>
>
>对于随机变量</script>X<script type="math/tex; ">和</script>Y<script type="math/tex; ">的独立性，有一个等价的数学公式：
></script><script type="math/tex; mode=display">
>P(X,Y)=P(X)P(Y)​
></script><script type="math/tex; mode=display">
>我们有时也会讨论条件独立，就是当我们当我们知道一个随机变量（或者更一般地，一组随机变量）的值时，那么其它随机变量之间相互独立。
>
>正式地，我 们说"给定</script>Z<script type="math/tex; ">，</script>X<script type="math/tex; ">和</script>Y<script type="math/tex; ">条件独立"，如果：
></script><script type="math/tex; mode=display">
>P(X|Z)=P(X|Y,Z)
></script><script type="math/tex; mode=display">
>或者等价的：
></script><script type="math/tex; mode=display">
>P(X,Y|Z)=P(X|Z)P(Y|Z)
></script><script type="math/tex; mode=display">
>机器学习(Andrew Ng)的课中会有一个朴素贝叶斯假设就是条件独立的一个例子。
>
>该学习算法对内容做出假设，用未分辨电子邮件是否为垃圾邮件。假设无论邮件是否为垃圾邮件，单词</script>x<script type="math/tex; ">出现在邮件中的概率条件独立于单词</script>y<script type="math/tex; ">。
>
>很明显这个假设不是不失一般性的，因为某些单词几乎总是同时出现。然而最终结果是，这个简单的假设对结果的影响并不大，且无论如何都可以让我们快速判别垃圾邮件。
>
>

# 链式法则和贝叶斯定理

>我们现在给出两个与联合分布和条件分布相关的，基础但是重要的可操作定理。
>
>第一个叫做`链式法则`，它可以看做等式(2)对于多变量的一般形式。
>**定理1**（`链式法则`）：
></script><script type="math/tex; mode=display">
>P(X_1,X_2,...,X_n)=P(X_1)P(X_2|X_1)...P(X_n|X_1,X_2,...X_{n-1})
></script><script type="math/tex; mode=display">
>链式法则通常用于计算多个随机变量的联合概率，特别是在变量之间相互为(条件)独立时会非常有用。
>
>注意，在使用链式法则时，我们可以选择展开随机变量的顺序；选择正确的顺序通常可以让概率的计算变得更加简单。
>
>第二个要介绍的是`贝叶斯定理`。
>
>利用贝叶斯定理，我们可以通过条件概率</script>P(Y|X)<script type="math/tex; ">算出</script>P(XIY)<script type="math/tex; ">，从某种意义上说就是交换条件。
>
>它也可以通过等式(2)推导出。
>**定理2**（`贝叶斯定理`）：
></script><script type="math/tex; mode=display">
>P(X|Y)=\frac{P(Y|X)P(X)}{P(Y)}
></script><script type="math/tex; mode=display">
>记得，如果</script>P(Y)<script type="math/tex; ">没有给出，我们可以用等式(1)找到它：
></script><script type="math/tex; mode=display">
>P(Y)=\sum_{a \in Val(X)}{P(X=a,Y)}=\sum_{a \in Val(X)}{P(Y|X=a)P(X=a)}
></script><script type="math/tex; mode=display">
>这种等式(1)的应用有时也被称为全概率公式，贝叶斯定理可以推广到多个随机变量的情况。
>
>在有疑问的时候，我们都可以参考条件概率的定义方式，弄清楚其细节。
>**Example7**: 考虑以下的条件概率：</script>P(X,Y|Z)<script type="math/tex; ">和</script>(X|Y,Z)<script type="math/tex; mode=display">
></script><script type="math/tex; mode=display">
>P(X,Y|Z)=\frac{P(Z|X,Y)P(X,Y)}{P(Z)}=\frac{P(Y,Z|X)P(X)}{P(Z)}
></script><script type="math/tex; mode=display">
>
></script><script type="math/tex; mode=display">
>P(X|Y,Z)=\frac{P(Y|X,Z)P(X,Z)}{P(Y,Z)}=\frac{P(Y|X,Z)P(X|Z)P(Z)}{P(Y|Z)P(Z)}=\frac{P(Y|X,Z)P(X|Z)}{P(Y|Z)}
></script><script type="math/tex; mode=display">
>
>

# 离散分布和连续分布

>`离散分布:概率质量函数`: 就一个离散分布而言，我们是指这种基本分布的随机变量只能取有限多个不同的值（或者样本空间有限）。
>在定义一个离散分布时，我们可以简单地列举出随机变量取每一个可能值的概率。
>
>这种列举方式称为概率质量函数（probability mass function[PMF])，因为它将（总概率的）每一个单元块分开，并将它们和随机变量可以取的不同值对应起来。这个可以类似的扩展到联合分布和条件分布。
>`连续分布:概率密度函数`: 对连续分布而言，我们是指这种基本分布的随机变量能取无限多个不同值（或者说样本空间是无限的）。
>连续分布相比离散分布来说是一种更加需要揣摩的情况，因为如果我们将每一个值取非零质量数，那么总质量相加就会是一个无限值，这样就不符合总概率相加等于1的要求。
>
>​	在定义一个连续分布时，我们会使用`概率密度函数（probability density function[PDF]）`。
>
>概率密度函数f是一个非负，可积(分)的函数，类似于：
></script><script type="math/tex; mode=display">
>\int _{Val(X)}{f(x)dx}=1
></script><script type="math/tex; mode=display">
>符合PDF </script>f<script type="math/tex; "> 的随机变量</script>X<script type="math/tex; ">的概率分布可以用如下公式计算：
></script><script type="math/tex; mode=display">
>P(a \leq X \leq b )= \int _{a}^{b}{f(x)dx}
></script><script type="math/tex; mode=display">
>注意，特别地，默认连续分布的随机变量取任意单一值的概率为零。
>
>
>
>**Example8**：(均匀分布）假设随机变量</script>X<script type="math/tex; ">在</script>[0,1]<script type="math/tex; ">上均匀分布，则对应的PDF为：
></script><script type="math/tex; mode=display">
>f(x)=\left\{
>\begin{aligned}
>1 \quad {if0 \leq x \leq b}\\
>0   \quad {otherwise}
>\end{aligned}
>\right.
></script><script type="math/tex; mode=display">
>我们可以确定</script> \int<em>{0}^{1}{dx}<script type="math/tex; ">为1，因此</script>f<script type="math/tex; ">为PDF。计算</script>X<script type="math/tex; ">的概率小于</script>1/2<script type="math/tex; ">.
></script><script type="math/tex; mode=display">
>P(X \leq \frac{1}{2})=\int _{0}^{\frac{1}{2}}{1dx}={|x|}_0^{\frac{1}{2}}=\frac{1}{2}
></script><script type="math/tex; mode=display">
>更一般地，假设</script>X<script type="math/tex; ">在</script>[a,b]<script type="math/tex; ">上均匀分布，那么PDF即为：
></script><script type="math/tex; mode=display">
>f(x)=\left\{
>\begin{aligned}
>\frac{1}{b-a} \quad {if0 \leq x \leq b}\\
>0   \quad {otherwise}
>\end{aligned}
>\right.
></script><script type="math/tex; mode=display">
>有时我们也会讨论累积分布函数，这种函数给出了随机变量在小于某一值的概率。
>
>`累积分布函数`</script>F<script type="math/tex; ">和`基本概率密度函数`</script>f<script type="math/tex; ">的关系如下：
></script><script type="math/tex; mode=display">
>F(b)=P(X \leq b)= \int_{-\infty}^{b}{f(x)dx}
></script><script type="math/tex; mode=display">
>因此，</script>F(x)= \int f(x)dx<script type="math/tex; ">(就不定积分而言）。
>
>
>
>要将连续分布的定义扩展到联合分布，需要把概率密度函数扩展为多个参数，即：
></script><script type="math/tex; mode=display">
>P(a_1 \leq X_1 \leq b_1, a_2 \leq X_2 \leq b_2,...a_n \leq X_n \leq b_n)=\int_{a_1}^{b_1}{\int _{a_2}^{b_2}{... \int _{a_n}^{b_n}{f(x_1,x_2,...,x_n)d_{x1}d_{x2}...d_{xn}}}}
></script><script type="math/tex; mode=display">
>将条件分布扩展到连续随机变量时，会遇到一个问题——连续随机变量在单个值上的概率为0，因此等式(2)不成立，因为分母等于0。
>
>为了定义连续变量的条件分布，要令</script>f(x,y)<script type="math/tex; ">为</script>X<script type="math/tex; ">和</script>Y<script type="math/tex; ">的联合分布。
>
>通过分析，我们能看到基于分布</script>P(Y|X)<script type="math/tex; ">的PDF </script>f(y|x)<script type="math/tex; "> 为：
></script><script type="math/tex; mode=display">
>f(y|x)=\frac{f(x,y)}{f(x)}
></script><script type="math/tex; mode=display">
>即如果直接用</script>P<script type="math/tex; ">的话，</script>P<script type="math/tex; ">可能在分母为零，所以用</script>f<script type="math/tex; ">，通过</script>f<script type="math/tex; ">积分间接得到</script>P<script type="math/tex; ">，例如：
></script><script type="math/tex; mode=display">
>P(a \leq Y \leq b |X=c)=\int_{a}^{b}{f(y|c)dy}=\int_{a}^{b}{\frac{f(c,y)}{f(c)}dy}
></script><script type="math/tex; mode=display">
>

# 期望

>我们对随机变量做的最常见的操作之一就是计算它的期望，也就是它的平均值(mean)，期望值(expected value)，或一阶矩(first moment)。
>
>随机变量的期望记为</script>E(x)<script type="math/tex; ">，计算公式：
>
></script><script type="math/tex; mode=display">
>E(x)=\sum_{a \in Val(x)}{aP(X=a)}或E(x)=\int_{a \in Val(x)}{xf(x)dx}
></script><script type="math/tex; mode=display">
>**Example9**: 令</script>X<script type="math/tex; ">为投掷一个均匀散子的结果，则</script>X<script type="math/tex; ">的期望为：
></script><script type="math/tex; mode=display">
>E(X)=(1)\frac{1}{6}+(2)\frac{1}{6}+...+(1)\frac{6}{6}=3\frac{1}{2}
></script><script type="math/tex; mode=display">
>​	有时我们可能会对计算随机变量</script>X<script type="math/tex; ">的某一函数f的期望值</script>f<script type="math/tex; ">感兴趣，再次重申，随机变量本身也是一个函数，因此最简单的考虑方法是定义一个新的随机变量</script>Y=f(X)<script type="math/tex; ">，然后计算</script>Y<script type="math/tex; ">的期望。
>
>当使用指示变量时，一个有用的判别方式是： 
>
></script><script type="math/tex; mode=display">
>E(X)=P(X=1), 其中X为指示变量 
></script><script type="math/tex; mode=display">
>此处可以脑补</script>X<script type="math/tex; ">还有一个取值为0，即</script>E(x)=1 \times P(X=1)+0 \times P(X=0)=P(X=1)<script type="math/tex; "> 
>
>当遇到随机变量的和时，一个最重要的规则之一是线性期望(linearity of expectations)。
>**定理3**(`线性期望`): 令</script>X_1,X_2,...,X_n<script type="math/tex; ">为(可能是独立的)随机变量：
></script><script type="math/tex; mode=display">
>E(X_1,X_2,...+X_n)=E(X_1)+E(x_2)+...+E(X_n)
></script><script type="math/tex; mode=display">
>期望为线性函数。
>
>期望的线性非常强大，因为它对于变量是否独立没有限利。当我们对随机变显的结果进行处理时，通常没什么可说的，但是，当随机变量相互独立时有
>
>**定理4**：令</script>X<script type="math/tex; ">和</script>Y<script type="math/tex; ">为相互独立的随机变量，则： 
></script><script type="math/tex; mode=display">
>E(XY)=E(X)E(Y)
></script><script type="math/tex; mode=display">
>



# 方差

> > 一个随机变显的方差描述的是它的商散程度，也就是该变量离其期望值的距离。
> >
> > 一个实随机变量的方差也称为它的二阶矩或二阶中心动差，恰巧也是它的二阶累积量，方差的算术平方根称为该随机变量的标准差。
>
> 方差的定义：
> </script><script type="math/tex; mode=display">
> Var(X)=E((X-E(X))^2)
> </script><script type="math/tex; mode=display">
> 随机变量的方差通常记为</script>\sigma ^2<script type="math/tex; ">，给它取平方的原因是因为我们通常想要找到</script> \sigma<script type="math/tex; ">，也就是`标准差`。
>
> 方差和标准差可以用公式</script>\sigma=\sqrt{Var(X)}<script type="math/tex; ">相关联。
>
> 为了找到随机变量</script>X<script type="math/tex; ">的方差，通常用以下替代公式更简单：
> </script><script type="math/tex; mode=display">
> Var(X)=E(X^2)-(E(X))^2
> </script><script type="math/tex; mode=display">
> 注意，不同于期望|方差不是关于随机变量</script>X<script type="math/tex; ">的线性函数，事实上，我们可以证明</script>(aX+b)<script type="math/tex; ">的方差为：
> </script><script type="math/tex; mode=display">
> Var(aX+b)=a^2Var(X)
> </script><script type="math/tex; mode=display">
> 如果随机变量</script>X<script type="math/tex; ">和</script>Y<script type="math/tex; ">相互独立，那么：
> </script><script type="math/tex; mode=display">
> Var(X+Y)=Var(X)Var(Y),如果X \bot Y
> </script><script type="math/tex; mode=display">
> 有时我们也会讨论两个随机变量的协方差，它可以用来威量两个随机变量的相关性，定义如下：
> </script><script type="math/tex; mode=display">
> Cov(X,Y)=E((X-E(X))(Y-E(Y)))
> </script><script type="math/tex; mode=display">
> 

# 伯努利、泊松、高斯分布

>  `伯努利(Bernoulli)分布`: 伯努利分布是最基础的概率分布之一，一个服从伯努利分布的随机变量有两种取值</script>{ 0,1}<script type="math/tex; ">，它能通过一个变量</script>p<script type="math/tex; ">未表示其概率，为了方便我们令</script>P(X=1)<script type="math/tex; ">为</script>p<script type="math/tex; ">。
>
>  它通常用于预测试验是否成功。有时将一个服从伯努利分布的变量</script>X<script type="math/tex; ">的概率分布按如下表示会很有用：
>  </script><script type="math/tex; mode=display">
>  P(X)=p^x(1-p)^{1-x}
>  </script><script type="math/tex; mode=display">
>  一个伯努利分布起作用的例子是Lecture Notes1中的分类任务。
>
>  为了给这个任务开发一个逻辑回归算法，对于特征来说，我们假设标签遵循伯努利概率分布。
>
>  
>
>  `泊松(Poisson)分布`: 泊松分布是一种非常有用的概率分布，通常用于处理事件发生次数的概率分布。
>
>  在给定一个事件发生的固定平均概率，并且在该段事件内事件发生相互独立时，它可以用来度量单位间内事件发生的次数，它包含一个参数——平均事件发生率入。
>
>  泊松分布的概率质量函数为：
>  </script><script type="math/tex; mode=display">
>  P(X=k)=\frac{exp(-\lambda )\lambda^k}{k!}
>  </script><script type="math/tex; mode=display">
>  服从泊松分布的随机变量的平均值为</script>\lambda<script type="math/tex; ">，其方差也为</script>\lambda<script type="math/tex; ">，</script>E(X)=V(X)=\lambda<script type="math/tex; mode=display">
>
>  
>
>  `高斯(Gaussian)分布`: 高斯分布也就是正态分布，是概率论中最”通用”的概率分布之一，并且在很多环境中都有出现。
>
>  例如，在试验数量很大时用在二项分布的近似处理中，或者在平均事件发生率很高时用于泊松分布。
>
>  它还和大数定理相关。对于很多问题来说，我们还会经常假设系统中的噪声服从高斯分布。
>
>  ![1569938605696](res/Machine%20Learning%20Base/1569938605696.png)
>
>  上图为不同期望和方差下的高斯分布。
>  高斯分布由两个参数决定：期望</script>\mu<script type="math/tex; ">和方差</script>\sigma ^2<script type="math/tex; ">。
>
>  其概率密度函数为：
>  </script><script type="math/tex; mode=display">
>  f(x)=\frac{1}{\sqrt{2 \pi \sigma}}exp(-\frac{(x-\mu)^2}{2 \sigma ^2})
>  </script><script type="math/tex; mode=display">
>  为了更好的感受概率分布随着期望和方差的改变，在上图中绘利了三种不同的高斯分布。
>  一个</script>k<script type="math/tex; ">维多变量高斯分布用参数</script>(\mu,\sum )<script type="math/tex; ">表示，其中，</script>\mu<script type="math/tex; ">为</script> \mathbb{R} ^k<script type="math/tex; ">上的期望矢量，</script>\sum<script type="math/tex; ">为</script>\mathbb{R} ^{k \times k}<script type="math/tex; ">上的协方差矩阵，
>
>  也就是说</script>\sum</em>{ii}=Var(X<em>i)<script type="math/tex; ">且</script>\sum</em>{ij}=Cov(X_i,Y_j)<script type="math/tex; ">。
>
>  其概率密度函数由输入的矢量定义：
>  </script><script type="math/tex; mode=display">
>  f(x)=\frac{1}{\sqrt{2 \pi ^k |\sum|}}exp(-\frac{1}{2}(x-\mu)^T \sum^{-1}{x-\mu})
>  </script><script type="math/tex; mode=display">
>  (我们标记矩阵</script>A<script type="math/tex; ">的行列式为</script>|A|<script type="math/tex; ">，其转置为</script>A^{-1}<script type="math/tex; ">）
>
>  

# Jenson不等式

>有时我们会计算一个函数对某个随机变量的期望，通常我们只需要一个区间而不是具体的某个值。在这种情况下，如果该函数是凸函数或 者凹函数，通过Jenson不等式，我们可以通过计算随机变量自身期望处的函数值来获得一个区间。
>
>![1569939436509](res/Machine%20Learning%20Base/1569939436509.png)
>
>(上图为Jenson不等式图示)
>
>**定理5(Jenson不等式)**: 令</script>X<script type="math/tex; ">为一个随机变量，</script>f<script type="math/tex; ">为凸函数，那么：
></script><script type="math/tex; mode=display">
>F(E(X)) \leq E(f(X))
></script><script type="math/tex; mode=display">
>如果</script>f<script type="math/tex; ">为凹函数，那么：
></script><script type="math/tex; mode=display">
>f(E(X)) \geq E(f(X))
></script>$$
&#x5C3D;&#x7BA1;&#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x7528;&#x4EE3;&#x6570;&#x8868;&#x793A;Jenson&#x4E0D;&#x7B49;&#x5F0F;&#xFF0C;&#x4F46;&#x662F;&#x901A;&#x8FC7;&#x4E00;&#x5F20;&#x56FE;&#x66F4;&#x5BB9;&#x6613;&#x7406;&#x89E3;&#x3002;</p>
<p>&#x4E0A;&#x56FE;&#x4E2D;&#x7684;&#x51FD;&#x6570;&#x4E3A;&#x4E00;&#x4E2A;&#x51F9;&#x51FD;&#x6570;&#xFF0C;&#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x770B;&#x5230;&#x8BE5;&#x51FD;&#x6570;&#x4EFB;&#x610F;&#x4E24;&#x70B9;&#x4E4B;&#x95F4;&#x7684;&#x76F4;&#x7EBF;&#x90FD;&#x5728;&#x51FD;&#x6570;&#x7684;&#x4E0A;&#x65B9;&#xFF0C;&#x4E5F;&#x5C31;&#x662F;&#x8BF4;&#xFF0C;&#x5982;&#x679C;&#x4E00;&#x4E2A;&#x968F;&#x673A;&#x53D8;&#x91CF;&#x53EA;&#x80FD;&#x53D6;&#x4E24;&#x4E2A;&#x503C;&#xFF0C;&#x90A3;&#x4E48;Jenson&#x4E0D;&#x7B49;&#x5F0F;&#x6210;&#x7ACB;&#x3002;&#x8FD9;&#x4E2A;&#x4E5F;&#x53EF;&#x4EE5;&#x6BD4;&#x8F83;&#x76F4;&#x63A5;&#x5730;&#x63A8;&#x5E7F;&#x5230;&#x4E00;&#x822C;&#x968F;&#x673A;&#x53D8;&#x91CF;&#x3002;</p>
</blockquote>
<footer class="page-footer"><span class="copyright">Copyright &#xA9; narutohyc.com 2020 all right reserved&#xFF0C;powered by Gitbook</span><span class="footer-modification">&#x8BE5;&#x6587;&#x4EF6;&#x4FEE;&#x8BA2;&#x65F6;&#x95F4;&#xFF1A;
2020-01-27 12:33:22
</span></footer>
                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="机器学习基础_距离.html" class="navigation navigation-prev " aria-label="Previous page: 机器学习基础_距离">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="机器学习基础_线性代数基础.html" class="navigation navigation-next " aria-label="Next page: 机器学习基础_线性代数基础">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"机器学习基础_概率论基础","level":"1.2.2","depth":2,"next":{"title":"机器学习基础_线性代数基础","level":"1.2.3","depth":2,"path":"chapters/机器学习基础_线性代数基础.md","ref":"chapters/机器学习基础_线性代数基础.md","articles":[]},"previous":{"title":"机器学习基础_距离","level":"1.2.1","depth":2,"path":"chapters/机器学习基础_距离.md","ref":"chapters/机器学习基础_距离.md","articles":[]},"dir":"ltr"},"config":{"plugins":["-sharing","splitter","expandable-chapters-small","anchors","github","github-buttons","donate","sharing-plus","anchor-navigation-ex","favicon","mathjax","mermaid-gb3","tbfed-pagefooter"],"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"pluginsConfig":{"tbfed-pagefooter":{"copyright":"Copyright © narutohyc.com 2020","modify_label":"该文件修订时间：","modify_format":"YYYY-MM-DD HH:mm:ss"},"github":{"url":"https://github.com/narutohyc"},"splitter":{},"search":{},"sharing-plus":{"qq":false,"all":["facebook","google","twitter","instapaper","linkedin","pocket","stumbleupon"],"douban":false,"facebook":true,"weibo":false,"instapaper":false,"whatsapp":false,"hatenaBookmark":false,"twitter":true,"messenger":false,"line":false,"vk":false,"pocket":true,"google":false,"viber":false,"stumbleupon":false,"qzone":false,"linkedin":false},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"donate":{"alipay":"https://upload-images.jianshu.io/upload_images/15675864-5e5ba668035853d8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240","alipayText":"支付宝打赏","button":"赏","title":"","wechat":"https://upload-images.jianshu.io/upload_images/15675864-5e5ba668035853d8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240","wechatText":"微信打赏"},"fontsettings":{"theme":"white","family":"sans","size":2},"highlight":{},"mermaid-gb3":{},"anchor-navigation-ex":{"associatedWithSummary":true,"float":{"floatIcon":"fa fa-navicon","level1Icon":"","level2Icon":"","level3Icon":"","showLevelIcon":false},"mode":"float","multipleH1":true,"pageTop":{"level1Icon":"","level2Icon":"","level3Icon":"","showLevelIcon":false},"printLog":false,"showGoTop":true,"showLevel":false},"favicon":{"shortcut":"https://upload-images.jianshu.io/upload_images/15675864-5e5ba668035853d8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240","bookmark":"https://upload-images.jianshu.io/upload_images/15675864-5e5ba668035853d8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240","appleTouch":"https://upload-images.jianshu.io/upload_images/15675864-5e5ba668035853d8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240","appleTouchMore":{"120x120":"https://upload-images.jianshu.io/upload_images/15675864-5e5ba668035853d8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240","180x180":"https://upload-images.jianshu.io/upload_images/15675864-5e5ba668035853d8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"}},"github-buttons":{"buttons":[{"user":"narutohyc","repo":"bk_machineLearning","type":"star","size":"small","count":true}]},"mathjax":{"forceSVG":false,"version":"2.6-latest"},"expandable-chapters-small":{},"sharing":{"qq":false,"all":["google","facebook","weibo","twitter","qq","qzone","linkedin","pocket"],"douban":false,"facebook":false,"weibo":false,"instapaper":false,"whatsapp":false,"hatenaBookmark":false,"twitter":false,"messenger":false,"line":false,"vk":false,"pocket":false,"google":false,"viber":false,"stumbleupon":false,"qzone":false,"linkedin":false},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":true},"anchors":{}},"theme":"default","author":"narutohyc","pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"variables":{},"title":"机器学习相关学习记录","language":"zh-hans","links":{"sidebar":{"我的狗窝":"https://github.com/narutohyc"}},"gitbook":"*","description":"记录 机器学习 的学习和一些技巧的使用"},"file":{"path":"chapters/机器学习基础_概率论基础.md","mtime":"2020-01-27T12:33:22.855Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2020-01-27T12:34:05.479Z"},"basePath":"..","book":{"language":""}});
        });
    </script>
</div>

        
    
    <script src="../gitbook/gitbook.js"></script>
    <script src="../gitbook/theme.js"></script>
    
        
        <script src="../gitbook/gitbook-plugin-splitter/splitter.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-expandable-chapters-small/expandable-chapters-small.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-github/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-github-buttons/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-donate/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-sharing-plus/buttons.js"></script>
        
    
        
        <script src="https://cdn.mathjax.org/mathjax/2.6-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-mathjax/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-mermaid-gb3/book/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    <script src="../gitbook/gitbook-plugin-mermaid-gb3/mermaid/mermaid.min.js"></script>

    </body>
</html>

