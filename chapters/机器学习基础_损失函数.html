<!DOCTYPE HTML>
<html lang="zh-hans">
<head>
<meta charset="utf-8"/>
<meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
<title>机器学习基础_损失函数 · 机器学习相关学习记录</title>
<meta content="IE=edge" http-equiv="X-UA-Compatible"/>
<meta content="" name="description"/>
<meta content="GitBook 3.2.3" name="generator"/>
<meta content="narutohyc" name="author"/>
<link href="../gitbook/style.css" rel="stylesheet"/>
<link href="../gitbook/gitbook-plugin-splitter/splitter.css" rel="stylesheet"/>
<link href="../gitbook/gitbook-plugin-expandable-chapters-small/expandable-chapters-small.css" rel="stylesheet"/>
<link href="../gitbook/gitbook-plugin-anchors/plugin.css" rel="stylesheet"/>
<link href="../gitbook/gitbook-plugin-donate/plugin.css" rel="stylesheet"/>
<link href="../gitbook/gitbook-plugin-anchor-navigation-ex/style/plugin.css" rel="stylesheet"/>
<link href="../gitbook/gitbook-plugin-mermaid-gb3/mermaid/mermaid.css" rel="stylesheet"/>
<link href="../gitbook/gitbook-plugin-tbfed-pagefooter/footer.css" rel="stylesheet"/>
<link href="../gitbook/gitbook-plugin-code/plugin.css" rel="stylesheet"/>
<link href="../gitbook/gitbook-plugin-search-plus/search.css" rel="stylesheet"/>
<link href="../gitbook/gitbook-plugin-lightbox/css/lightbox.min.css" rel="stylesheet"/>
<link href="../gitbook/gitbook-plugin-change_girls/girls.css" rel="stylesheet"/>
<link href="../gitbook/gitbook-plugin-pageview-count/plugin.css" rel="stylesheet"/>
<link href="../gitbook/gitbook-plugin-highlight/website.css" rel="stylesheet"/>
<link href="../gitbook/gitbook-plugin-fontsettings/website.css" rel="stylesheet"/>
<link href="../gitbook/gitbook-plugin-theme-comscore/test.css" rel="stylesheet"/>
<meta content="true" name="HandheldFriendly"/>
<meta content="width=device-width, initial-scale=1, user-scalable=no" name="viewport"/>
<meta content="yes" name="apple-mobile-web-app-capable"/>
<meta content="black" name="apple-mobile-web-app-status-bar-style"/>
<link href="../gitbook/images/apple-touch-icon-precomposed-152.png" rel="apple-touch-icon-precomposed" sizes="152x152"/>
<link href="../gitbook/images/favicon.ico" rel="shortcut icon" type="image/x-icon"/>
<link href="特征工程.html" rel="next"/>
<link href="机器学习基础_最优化理论.html" rel="prev"/>
<link href="./chapters/res/other/favicon.ico" rel="shortcut icon" type="image/x-icon"/>
<link href="./chapters/res/other/favicon.ico" rel="apple-touch-icon-precomposed" sizes="152x152"/>
<link href="../https:/upload-images.jianshu.io/upload_images/15675864-5e5ba668035853d8.png" rel="shortcut icon" type="image/x-icon"/>
<link href="../https:/upload-images.jianshu.io/upload_images/15675864-5e5ba668035853d8.png" rel="bookmark" type="image/x-icon"/>
<link href="../https:/upload-images.jianshu.io/upload_images/15675864-5e5ba668035853d8.png" rel="apple-touch-icon"/>
<link href="../https:/upload-images.jianshu.io/upload_images/15675864-5e5ba668035853d8.png" rel="apple-touch-icon" sizes="120x120"/>
<link href="../https:/upload-images.jianshu.io/upload_images/15675864-5e5ba668035853d8.png" rel="apple-touch-icon" sizes="180x180"/>
<style>
    @media only screen and (max-width: 640px) {
        .book-header .hidden-mobile {
            display: none;
        }
    }
    </style>
<script>
        window["gitbook-plugin-github-buttons"] = {"buttons":[{"user":"narutohyc","repo":"bk_machineLearning","type":"star","size":"small","count":true}]};
    </script>
</head>
<body>
<div class="book">
<div class="book-summary">
<div id="book-search-input" role="search">
<input placeholder="输入并搜索" type="text"/>
</div>
<nav role="navigation">
<ul class="summary">
<li>
<a class="custom-link" href="https://github.com/narutohyc" target="_blank">我的狗窝</a>
</li>
<li class="divider"></li>
<li class="chapter" data-level="1.1" data-path="../">
<a href="../">
<b>1.1.</b>
                    
                    Introduction
            
                </a>
</li>
<li class="chapter" data-level="1.2" data-path="机器学习基础.html">
<a href="机器学习基础.html">
<b>1.2.</b>
                    
                    机器学习基础
            
                </a>
<ul class="articles">
<li class="chapter" data-level="1.2.1" data-path="机器学习基础_距离.html">
<a href="机器学习基础_距离.html">
<b>1.2.1.</b>
                    
                    机器学习基础_距离
            
                </a>
</li>
<li class="chapter" data-level="1.2.2" data-path="机器学习基础_概率论基础.html">
<a href="机器学习基础_概率论基础.html">
<b>1.2.2.</b>
                    
                    机器学习基础_概率论基础
            
                </a>
</li>
<li class="chapter" data-level="1.2.3" data-path="机器学习基础_线性代数基础.html">
<a href="机器学习基础_线性代数基础.html">
<b>1.2.3.</b>
                    
                    机器学习基础_线性代数基础
            
                </a>
</li>
<li class="chapter" data-level="1.2.4" data-path="机器学习基础_微积分基础.html">
<a href="机器学习基础_微积分基础.html">
<b>1.2.4.</b>
                    
                    机器学习基础_微积分基础
            
                </a>
</li>
<li class="chapter" data-level="1.2.5" data-path="机器学习基础_最优化理论.html">
<a href="机器学习基础_最优化理论.html">
<b>1.2.5.</b>
                    
                    机器学习基础_最优化理论
            
                </a>
</li>
<li class="chapter active" data-level="1.2.6" data-path="机器学习基础_损失函数.html">
<a href="机器学习基础_损失函数.html">
<b>1.2.6.</b>
                    
                    机器学习基础_损失函数
            
                </a>
</li>
</ul>
</li>
<li class="chapter" data-level="1.3" data-path="特征工程.html">
<a href="特征工程.html">
<b>1.3.</b>
                    
                    特征工程
            
                </a>
<ul class="articles">
<li class="chapter" data-level="1.3.1" data-path="特征工程_归一化.html">
<a href="特征工程_归一化.html">
<b>1.3.1.</b>
                    
                    特征工程_归一化
            
                </a>
</li>
<li class="chapter" data-level="1.3.2" data-path="特征工程_编码.html">
<a href="特征工程_编码.html">
<b>1.3.2.</b>
                    
                    特征工程_编码
            
                </a>
</li>
<li class="chapter" data-level="1.3.3" data-path="特征工程_特征组合.html">
<a href="特征工程_特征组合.html">
<b>1.3.3.</b>
                    
                    特征工程_特征组合
            
                </a>
</li>
<li class="chapter" data-level="1.3.4" data-path="特征工程_特征选择.html">
<a href="特征工程_特征选择.html">
<b>1.3.4.</b>
                    
                    特征工程_特征选择
            
                </a>
</li>
<li class="chapter" data-level="1.3.5" data-path="特征工程_文本表示模型.html">
<a href="特征工程_文本表示模型.html">
<b>1.3.5.</b>
                    
                    特征工程_文本表示模型
            
                </a>
</li>
<li class="chapter" data-level="1.3.6" data-path="特征工程_图像增强.html">
<a href="特征工程_图像增强.html">
<b>1.3.6.</b>
                    
                    特征工程_图像增强
            
                </a>
</li>
</ul>
</li>
<li class="chapter" data-level="1.4" data-path="模型评估.html">
<a href="模型评估.html">
<b>1.4.</b>
                    
                    模型评估
            
                </a>
<ul class="articles">
<li class="chapter" data-level="1.4.1" data-path="模型评估_评估指标.html">
<a href="模型评估_评估指标.html">
<b>1.4.1.</b>
                    
                    模型评估_评估指标
            
                </a>
</li>
<li class="chapter" data-level="1.4.2" data-path="模型评估_AB测试.html">
<a href="模型评估_AB测试.html">
<b>1.4.2.</b>
                    
                    模型评估_AB测试
            
                </a>
</li>
<li class="chapter" data-level="1.4.3" data-path="模型评估_过拟合和欠拟合.html">
<a href="模型评估_过拟合和欠拟合.html">
<b>1.4.3.</b>
                    
                    模型评估_过拟合和欠拟合
            
                </a>
</li>
<li class="chapter" data-level="1.4.4" data-path="模型评估_超参数选择.html">
<a href="模型评估_超参数选择.html">
<b>1.4.4.</b>
                    
                    模型评估_超参数选择
            
                </a>
</li>
<li class="chapter" data-level="1.4.5" data-path="模型评估_模型评估方法.html">
<a href="模型评估_模型评估方法.html">
<b>1.4.5.</b>
                    
                    模型评估_模型评估方法
            
                </a>
</li>
</ul>
</li>
<li class="chapter" data-level="1.5" data-path="降维.html">
<a href="降维.html">
<b>1.5.</b>
                    
                    降维
            
                </a>
<ul class="articles">
<li class="chapter" data-level="1.5.1" data-path="降维_PCA主成分分析.html">
<a href="降维_PCA主成分分析.html">
<b>1.5.1.</b>
                    
                    降维_PCA主成分分析
            
                </a>
</li>
<li class="chapter" data-level="1.5.2" data-path="降维_LDA线性判别分析.html">
<a href="降维_LDA线性判别分析.html">
<b>1.5.2.</b>
                    
                    降维_LDA线性判别分析
            
                </a>
</li>
</ul>
</li>
<li class="chapter" data-level="1.6" data-path="监督学习.html">
<a href="监督学习.html">
<b>1.6.</b>
                    
                    监督学习
            
                </a>
<ul class="articles">
<li class="chapter" data-level="1.6.1" data-path="监督学习_朴素贝叶斯分类.html">
<a href="监督学习_朴素贝叶斯分类.html">
<b>1.6.1.</b>
                    
                    监督学习_朴素贝叶斯分类
            
                </a>
</li>
<li class="chapter" data-level="1.6.2" data-path="监督学习_决策树.html">
<a href="监督学习_决策树.html">
<b>1.6.2.</b>
                    
                    监督学习_决策树
            
                </a>
</li>
<li class="chapter" data-level="1.6.3" data-path="监督学习_K近邻法.html">
<a href="监督学习_K近邻法.html">
<b>1.6.3.</b>
                    
                    监督学习_K近邻法
            
                </a>
</li>
<li class="chapter" data-level="1.6.4" data-path="监督学习_支持向量机.html">
<a href="监督学习_支持向量机.html">
<b>1.6.4.</b>
                    
                    监督学习_支持向量机
            
                </a>
</li>
<li class="chapter" data-level="1.6.5" data-path="监督学习_CRF.html">
<a href="监督学习_CRF.html">
<b>1.6.5.</b>
                    
                    监督学习_CRF
            
                </a>
</li>
</ul>
</li>
<li class="chapter" data-level="1.7" data-path="非监督学习.html">
<a href="非监督学习.html">
<b>1.7.</b>
                    
                    非监督学习
            
                </a>
<ul class="articles">
<li class="chapter" data-level="1.7.1" data-path="非监督学习_K均值.html">
<a href="非监督学习_K均值.html">
<b>1.7.1.</b>
                    
                    非监督学习_K均值
            
                </a>
</li>
<li class="chapter" data-level="1.7.2" data-path="非监督学习_Mean Shift均值漂移聚类.html">
<a href="非监督学习_Mean Shift均值漂移聚类.html">
<b>1.7.2.</b>
                    
                    非监督学习_Mean Shift均值漂移聚类
            
                </a>
</li>
<li class="chapter" data-level="1.7.3" data-path="非监督学习_DBSCAN基于密度的聚类方法.html">
<a href="非监督学习_DBSCAN基于密度的聚类方法.html">
<b>1.7.3.</b>
                    
                    非监督学习_DBSCAN基于密度的聚类方法
            
                </a>
</li>
<li class="chapter" data-level="1.7.4" data-path="非监督学习_Hierarchical Clustering层次聚类.html">
<a href="非监督学习_Hierarchical Clustering层次聚类.html">
<b>1.7.4.</b>
                    
                    非监督学习_Hierarchical Clustering层次聚类
            
                </a>
</li>
<li class="chapter" data-level="1.7.5" data-path="非监督学习_Spectral Clustering谱聚类.html">
<a href="非监督学习_Spectral Clustering谱聚类.html">
<b>1.7.5.</b>
                    
                    非监督学习_Spectral Clustering谱聚类
            
                </a>
</li>
</ul>
</li>
<li class="chapter" data-level="1.8" data-path="半监督学习.html">
<a href="半监督学习.html">
<b>1.8.</b>
                    
                    半监督学习
            
                </a>
</li>
<li class="chapter" data-level="1.9" data-path="集成学习.html">
<a href="集成学习.html">
<b>1.9.</b>
                    
                    集成学习
            
                </a>
</li>
<li class="chapter" data-level="1.10" data-path="强化学习.html">
<a href="强化学习.html">
<b>1.10.</b>
                    
                    强化学习
            
                </a>
</li>
<li class="divider"></li>
<li>
<a class="gitbook-link" href="https://www.gitbook.com" target="blank">
            本书使用 GitBook 发布
        </a>
</li>
</ul>
</nav>
</div>
<div class="book-body">
<div class="body-inner">
<div class="book-header" role="navigation">
<!-- Title -->
<h1>
<i class="fa fa-circle-o-notch fa-spin"></i>
<a href="..">机器学习基础_损失函数</a>
</h1>
</div>
<div class="page-wrapper" role="main" tabindex="-1">
<div class="page-inner">
<div class="search-plus" id="book-search-results">
<div class="search-noresults">
<section class="normal markdown-section">
<div id="anchor-navigation-ex-navbar"><i class="fa fa-navicon"></i><ul><li><span class="title-icon"></span><a href="#损失函数">1 损失函数</a></li><li><span class="title-icon"></span><a href="#经验误差风险">2 经验误差风险</a></li><li><span class="title-icon"></span><a href="#损失函数定义">3 损失函数定义</a></li><li><span class="title-icon"></span><a href="#模型泛化误差">4 模型泛化误差</a></li></ul></div><a href="#损失函数" id="anchorNavigationExGoTop"><i class="fa fa-arrow-up"></i></a><p><a data-lightbox="76113f3d-c08d-4fa6-813a-2c99f0e1c34e" data-title="异世界.png" href="res/other/异世界蕾姆_1.png"><img alt="异世界.png" src="res/other/异世界蕾姆_1.png"/></a></p>
<h1 id="损失函数">1 损失函数</h1>
<h1 id="经验误差风险">2 经验误差风险</h1>
<blockquote>
<p>假定我们的目的是学习一个模型，用以自动判断某产品评论是正面的还是负面的。</p>
<p>为了更好地对机器学习的基本流程进行描述，我们首先对有监督的二分类问题进行数学建模。假设我们有一个训练数据集，包含<script type="math/tex; ">n</script>个样本<script type="math/tex; ">\{x_i\}_{i=1}^n</script>，每个样本<script type="math/tex; ">x</script>；可以表示成一个<script type="math/tex; ">d</script>维的向量：<script type="math/tex; ">x_i \in X \subseteq R^d</script>。样本<script type="math/tex; ">x_{i}</script>被赋予了一个标签<script type="math/tex; ">y_i</script>，表征该样本属于正类还是负类：<script type="math/tex; ">y_i \in Y= \{+1,-1\}</script>。</p>
<p>假设我们最终想要通过机器学习获得一个分类模型<script type="math/tex; ">g:X \to R</script>，它以<script type="math/tex; ">X</script>空间内任意的<script type="math/tex; ">d</script>维向量为输入，通过一个由参数<script type="math/tex; ">w</script>驱动的变换，输出一个分数，然后取这个分数的符号，得到<script type="math/tex; ">Y</script>空间的预测标签：<script type="math/tex; ">sgn(g(x_i;w))</script>。那么现在的问题是：什么样的分类模型才是好的？如何才能学到一个好的分类模型呢？
   可以根据一个分类模型<script type="math/tex; ">g</script>在训练集上的表现来评价它的好坏。换言之，我们把<script type="math/tex; ">g</script>作用在每一个训练样本<script type="math/tex; ">x_i</script>；上，获得相应的输出值<script type="math/tex; ">g(x_i;w)</script>，然后把这个输出值与<script type="math/tex; ">x_i</script>本身的类别标签<script type="math/tex; ">y_i</script>，进行比对，如果二者相同就说明<script type="math/tex; ">g</script>在这个样本上实现了正确的分类，否则就判定它分类错误。这个判定可以用一个简单的示性误差函数加以表示：
<script type="math/tex; mode=display">
>\epsilon(w;x_i,y_i)=1_{|y_ig(x_i,w)|<0}
></script>
​    如果分类模型<script type="math/tex; ">g</script>把训练集里所有的样本或绝大部分样本都分到了正确的类别里，我们就说它是一个好的分类器；相反，如果<script type="math/tex; ">g</script>在很多样本上都做出了错误的判断，我们就说它不是一个好的分类器。这种定性的判断可以用一个称为<code>经验误差风险</code>的数值来进行定量衡量，也就是分类模型<script type="math/tex; ">g</script>在所有的训练样本上所犯错误的总和：
<script type="math/tex; mode=display">
>\hat{\epsilon}(w)=\sum_{i=1}^{n}{1_{|y_ig(x_i,w)|<0}}
></script>
​    如果<script type="math/tex; ">\hat{\epsilon}(w)**</script>**为0或者取值很小，我们就说<script type="math/tex; ">g</script>的经验误差风险很小，是一个不错的分类模型。反之，如果<script type="math/tex; ">\hat{\epsilon}(w)</script>很大，则对应的经验误差风险很大，<script type="math/tex; ">g</script>就不是一个好的分类模型。
​    通常，我们会通过在训练集上最小化经验误差风险来训练分类模型。换言之，通过调节<script type="math/tex; ">g</script>的参数<script type="math/tex; ">w</script>，使得经验误差风险。<script type="math/tex; ">\hat{\epsilon}(w)</script>不断下降，最终达到最小值的时候，我们就获得了一个所谓“最优”的分类模型。这件事说起来容易，实操起来还是有难度的，主要的问题出在。<script type="math/tex; ">\hat{\epsilon}(w)</script>的数学性质上。按照上面的定义，<script type="math/tex; ">\hat{\epsilon}(w)</script>是一组示性函数的和，因此是一个不连续、不可导的函数，不易优化。</p>
<p>​    为了解决这个问题，人们提出了<code>损失函数</code>的概念。所谓的损失函数就是和误差函数有一定的关系(例如是误差函数的上界)但具有更好的数学性质(比如连续、可导、凸性等)，比较容易进行优化。通过对经验损失风险的最小化，我们可以间接地实现对经验误差风险<script type="math/tex; ">\hat{\epsilon}(w)</script>的最小化。为了便于引用，我们用<script type="math/tex; ">\hat{l}(w)</script>来表示经验损失风险。
​    因为损失函数满足了连续可导的条件，所以在优化过程中选择面就比较宽了，有很多方法可供使用。我们既可以选择确定性的优化算法(包含以梯度下降法、坐标下降法为代表的一阶算法，以及以牛顿法、拟牛顿法为代表的二阶算法)，也可以选择随机性的优化算法(包括随机梯度下降法、随机坐标下降法、随机拟牛顿法等)。</p>
<p>​    当优化算法收敛以后，我们就得到了一个不错的模型。当然，这个“不错”的模型到底能有多好还要看损失函数的复杂程度。如果损失函数是个凸函数，则很容易通过上述方法找到全局最优模型；否则，多数情况下我们得到的只是局部最优模型。无论是哪种情况，未来我们将会使用这个学到的模型对未知的新样本进行分类。</p>
<p><a data-lightbox="38867885-0427-45f1-801d-096d216b848a" data-title="1571560658397" href="res/Machine%20Learning%20Base/1571560658397.png"><img alt="1571560658397" src="res/Machine%20Learning%20Base/1571560658397.png"/></a></p>
</blockquote>
<h1 id="损失函数定义">3 损失函数定义</h1>
<blockquote>
<p>在二分类问题中，<script type="math/tex; ">0-1</script>误差是最终的评价准则，但是因为它不是一个连续的凸函数，直接用它来指导模型优化的过程未必是一个好的选择。为了解决这个问题，人们通常使用损失函数作为<script type="math/tex; ">0-1</script>误差的一个凸近似或者凸上界，然后通过最小化损失函数，来间接地达到最小化<script type="math/tex; ">0-1</script>误差的目的。本节将介绍几种典型的损失函数。</p>
<p><code>Hinge损失函数</code>衡量的是预测模型的输出的符号和类别标签的符号是否一致以及一致的程度。</p>
<p>其具体数学形式如下：
<script type="math/tex; mode=display">
>l(w;x,y)=max\{0,1-yg(x;w)\}
></script>
​    从以上数学定义可以看出：当<script type="math/tex; ">g(x;w)</script>和<script type="math/tex; ">y</script>符号相同且乘积数值超过1时，损失函数取值为0；否则，将有一个线性的损失(二者符号不同时，乘积的绝对值越大，损失越大)。Hinge损失函数是一个连续凸函数，但是它在0点不可导，人们通常会选择次导数集合中的任意一个数值参与优化过程。我们从图2.3可以清晰地看出，Hinge损失是<script type="math/tex; ">0-1</script>误差的上界，因此通过最小化Hinge损失，可以有效地减小<script type="math/tex; ">0-1</script>误差，从而提高分类性能。</p>
<p><a data-lightbox="7e55604e-b4c3-4824-b7bc-33413f63dfab" data-title="1571560745676" href="res/Machine%20Learning%20Base/1571560745676.png"><img alt="1571560745676" src="res/Machine%20Learning%20Base/1571560745676.png"/></a><code>指数损失函数</code>指数损失函数也是<script type="math/tex; ">0-1</script>误差的上界，它的具体形式如下（参见图2.4）：
<script type="math/tex; mode=display">
>l(x;x,y)=exp(-yg(x:w))
></script>
从以上定义可以看出，指数损失函数对于预测模型输出的符号与类别标签的符号不一致的情况有强烈的惩罚，相反，当二者符号一致且乘积数值较大时，损失函数的取值会非常小。指数损失函数的基本形状和Hinge损失函数很接近，只不过它对于符号不一致的情况的惩罚力度更大(指数力度vs.线性力度)，而且它是全程连续可导的凸函数，对于优化过程更加有利。</p>
<p><code>交叉熵损失函数</code>也是常用的损失函数之一，它假设预测模型以下述形式决定了标签的概率分布：
<script type="math/tex; mode=display">
>P(Y=1|x;w)=\frac{exp(g(x;w))}{exp(g(x;w))+exp(-g(x;w))}
></script>
并且试图衡量该概率与标签之间的差别。其数学定义如下（参见图2.5）：
<script type="math/tex; mode=display">
>l(w;x,y)-\sum_z \in \{-1,1 \}{I_{|y=z|}}{}{logP(Y=z|x;w)}
></script>
可见，最小化交叉熵损失函数等价于最大化预测函数g所对应的条件似然函数。</p>
<p><a data-lightbox="d5513da6-5b39-4c7e-9c4c-4cca19c4f7ad" data-title="1571566807764" href="res/Machine%20Learning%20Base/1571566807764.png"><img alt="1571566807764" src="res/Machine%20Learning%20Base/1571566807764.png"/></a></p>
<p>从以上定义可以看出，对于正类的样本而言，当12预测模型的输出接近于1时，损失很小；而当预测模型的输出接近于0时，则产生一个很大的损失。相反，对于负类的样本而言，当预测模型的输出接近于1时，会产生很大的损失；而当预测模型的输出接近于0时，则损失很小。交叉熵损失函数也是一个全程连续可导的凸函数，并且是<script type="math/tex; ">0-1</script>误差的上界。图2.5交叉熵损失函数以上介绍了一些常用的损失函数。虽然它们和<script type="math/tex; ">0-1</script>误差在形式上有所差别，但是从统计意义上讲，它们存在着很强的关联关系。可以证明，在一定假设下，以上损失函数对于<script type="math/tex; ">0-1</script>误差而言都具有统计一致性，也就是说，当样本趋近于无穷多的时候，按照最小化损失函数找到的最优模型也是在<script type="math/tex; ">0-1</script>误差意义下的最优模型。这就给使用这些损失函数奠定了理论基础。</p>
</blockquote>
<h1 id="模型泛化误差">4 模型泛化误差</h1>
<blockquote>
<p>机器学习算法的最终目标是最小化期望损失风险(也就是模型在任意未知测试样本上的表现)：
<script type="math/tex; mode=display">
>\min_{g \in G}L(g)=E_{x,y \sim  P_{x,y}}l(g;x,y)
></script>
其中<script type="math/tex; ">G</script>是一个预先给定的函数族。
   由于数据的真实分布<script type="math/tex; ">P_{x,y}</script>.通常是不知道的，我们的可用信息来自于训练数据<script type="math/tex; ">S_n=\{(x_1,y_1),...,(x_n,y_n)\}</script>。因此，我们的学习目标转化为最小化经验风险：
<script type="math/tex; mode=display">
>\min_{g \in G}{\hat l(g)}=\frac{1}{n} \sum_{i=1}^{n}{l(g;x_i,y_i)}
></script>
当函数空间<script type="math/tex; ">G</script>受限时，比如我们只允许优化算法在那些范数小于<script type="math/tex; ">c</script>的函数子空间里进行搜索，亦即<script type="math/tex; ">G_c=\{g:g \in G, ||g||_G \leq c\}</script>，我们称相应的学习问题为正则经验风险最小化。
优化算法对(正则化)经验风险最小化问题进行求解，并在算法结束的第<script type="math/tex; ">T</script>次迭代中输出模型<script type="math/tex; ">\hat g_r</script>。我们希望所学习到的模型<script type="math/tex; ">\hat g_r</script>的期望风险<script type="math/tex; ">L(\hat g_r)</script>尽可能小，并将其定义为机器学习算法的泛化误差。</p>
</blockquote>
<p></p><footer class="page-footer"><span class="copyright">Copyright © narutohyc.com 2020 all right reserved，powered by Gitbook</span><span class="footer-modification">该文件修订时间：
2022-02-15 13:30:23
</span></footer><hr/><div id="vcomments"></div><script src="//unpkg.com/valine/dist/Valine.min.js"></script><script>new Valine({el: "#vcomments",appId: 'jQTfSSGRF0zp8yqaaa6bjeVQ-gzGzoHsz',appKey: 'FOXMptWOHC7cU1FxXt0LJj4o',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false})</script><p></p>
</section>
</div>
<div class="search-results">
<div class="has-results">
<h1 class="search-results-title"><span class="search-results-count"></span> results matching "<span class="search-query"></span>"</h1>
<ul class="search-results-list"></ul>
</div>
<div class="no-results">
<h1 class="search-results-title">No results matching "<span class="search-query"></span>"</h1>
</div>
</div>
</div>
</div>
</div>
</div>
<a aria-label="Previous page: 机器学习基础_最优化理论" class="navigation navigation-prev" href="机器学习基础_最优化理论.html">
<i class="fa fa-angle-left"></i>
</a>
<a aria-label="Next page: 特征工程" class="navigation navigation-next" href="特征工程.html">
<i class="fa fa-angle-right"></i>
</a>
</div>
<script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"机器学习基础_损失函数","level":"1.2.6","depth":2,"next":{"title":"特征工程","level":"1.3","depth":1,"path":"chapters/特征工程.md","ref":"chapters/特征工程.md","articles":[{"title":"特征工程_归一化","level":"1.3.1","depth":2,"path":"chapters/特征工程_归一化.md","ref":"chapters/特征工程_归一化.md","articles":[]},{"title":"特征工程_编码","level":"1.3.2","depth":2,"path":"chapters/特征工程_编码.md","ref":"chapters/特征工程_编码.md","articles":[]},{"title":"特征工程_特征组合","level":"1.3.3","depth":2,"path":"chapters/特征工程_特征组合.md","ref":"chapters/特征工程_特征组合.md","articles":[]},{"title":"特征工程_特征选择","level":"1.3.4","depth":2,"path":"chapters/特征工程_特征选择.md","ref":"chapters/特征工程_特征选择.md","articles":[]},{"title":"特征工程_文本表示模型","level":"1.3.5","depth":2,"path":"chapters/特征工程_文本表示模型.md","ref":"chapters/特征工程_文本表示模型.md","articles":[]},{"title":"特征工程_图像增强","level":"1.3.6","depth":2,"path":"chapters/特征工程_图像增强.md","ref":"chapters/特征工程_图像增强.md","articles":[]}]},"previous":{"title":"机器学习基础_最优化理论","level":"1.2.5","depth":2,"path":"chapters/机器学习基础_最优化理论.md","ref":"chapters/机器学习基础_最优化理论.md","articles":[]},"dir":"ltr"},"config":{"plugins":["-sharing","splitter","expandable-chapters-small","anchors","github","github-buttons","donate","sharing-plus","anchor-navigation-ex","mathjax","mermaid-gb3","tbfed-pagefooter","code","favicon","search-plus","-lunr","-search","lightbox","change_girls","theme-comscore","valine","pageview-count","favicon-absolute"],"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"pluginsConfig":{"tbfed-pagefooter":{"copyright":"Copyright © narutohyc.com 2020","modify_label":"该文件修订时间：","modify_format":"YYYY-MM-DD HH:mm:ss"},"github":{"url":"https://github.com/narutohyc"},"splitter":{},"change_girls":{"time":10,"urls":["https://plc.jj20.com/up/allimg/1115/012122143136/220121143136-2.jpg","https://plc.jj20.com/up/allimg/1115/111R1094405/21111P94405-1.jpg"]},"sharing-plus":{"qq":false,"all":["facebook","google","twitter","instapaper","linkedin","pocket","stumbleupon"],"douban":false,"facebook":true,"weibo":false,"instapaper":false,"whatsapp":false,"hatenaBookmark":false,"twitter":true,"messenger":false,"line":false,"vk":false,"pocket":true,"google":false,"viber":false,"stumbleupon":false,"qzone":false,"linkedin":false},"code":{"copyButtons":true},"donate":{"alipay":"https://i.loli.net/2021/01/12/Cdunm9AoBcHF5MI.png","alipayText":"alipay打赏","button":"欢迎打赏","title":"","wechat":"https://i.loli.net/2021/01/12/gmzASfCciIFXTyr.png","wechatText":"wechat打赏"},"favicon-absolute":{"appleTouchIconMore":{},"appleTouchIconPrecomposed152":"./chapters/res/other/favicon.ico","appleTouchIconPrecomposedMore":{},"favicon":"./chapters/res/other/favicon.ico"},"fontsettings":{"theme":"white","family":"sans","size":2},"highlight":{},"mermaid-gb3":{},"anchor-navigation-ex":{"associatedWithSummary":true,"float":{"floatIcon":"fa fa-navicon","level1Icon":"","level2Icon":"","level3Icon":"","showLevelIcon":false},"mode":"float","multipleH1":true,"pageTop":{"level1Icon":"","level2Icon":"","level3Icon":"","showLevelIcon":false},"printLog":false,"showGoTop":true,"showLevel":false},"favicon":{"shortcut":"https://upload-images.jianshu.io/upload_images/15675864-5e5ba668035853d8.png","bookmark":"https://upload-images.jianshu.io/upload_images/15675864-5e5ba668035853d8.png","appleTouch":"https://upload-images.jianshu.io/upload_images/15675864-5e5ba668035853d8.png","appleTouchMore":{"120x120":"https://upload-images.jianshu.io/upload_images/15675864-5e5ba668035853d8.png","180x180":"https://upload-images.jianshu.io/upload_images/15675864-5e5ba668035853d8.png"}},"lightbox":{"jquery":true,"sameUuid":false},"theme-comscore":{},"pageview-count":{},"github-buttons":{"buttons":[{"user":"narutohyc","repo":"bk_machineLearning","type":"star","size":"small","count":true}]},"mathjax":{"forceSVG":false,"version":"2.6-latest"},"expandable-chapters-small":{},"sharing":{"qq":true,"all":["google","facebook","weibo","twitter","qq","qzone","linkedin","pocket"],"douban":true,"facebook":true,"weibo":true,"instapaper":false,"whatsapp":false,"hatenaBookmark":false,"twitter":true,"messenger":false,"line":false,"vk":false,"pocket":false,"google":true,"viber":false,"stumbleupon":false,"qzone":true,"linkedin":false},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":true},"anchors":{},"valine":{"avatar":"","lang":"zh-CN","pageSize":10,"placeholder":"Just go go","recordIP":false,"appId":"jQTfSSGRF0zp8yqaaa6bjeVQ-gzGzoHsz","appKey":"FOXMptWOHC7cU1FxXt0LJj4o"},"search-plus":{}},"theme":"default","author":"narutohyc","pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"variables":{},"title":"机器学习相关学习记录","language":"zh-hans","links":{"sidebar":{"我的狗窝":"https://github.com/narutohyc"}},"gitbook":"*","description":"记录 机器学习 的学习和一些技巧的使用"},"file":{"path":"chapters/机器学习基础_损失函数.md","mtime":"2022-02-15T13:30:23.521Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2022-02-15T13:32:13.117Z"},"basePath":"..","book":{"language":""}});
        });
    </script>
</div>
<script src="../gitbook/gitbook.js"></script>
<script src="../gitbook/theme.js"></script>
<script src="../gitbook/gitbook-plugin-splitter/splitter.js"></script>
<script src="../gitbook/gitbook-plugin-expandable-chapters-small/expandable-chapters-small.js"></script>
<script src="../gitbook/gitbook-plugin-github/plugin.js"></script>
<script src="../gitbook/gitbook-plugin-github-buttons/plugin.js"></script>
<script src="../gitbook/gitbook-plugin-donate/plugin.js"></script>
<script src="../gitbook/gitbook-plugin-sharing-plus/buttons.js"></script>
<script src="https://cdn.mathjax.org/mathjax/2.6-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script src="../gitbook/gitbook-plugin-mathjax/plugin.js"></script>
<script src="../gitbook/gitbook-plugin-mermaid-gb3/book/plugin.js"></script>
<script src="../gitbook/gitbook-plugin-code/plugin.js"></script>
<script src="../gitbook/gitbook-plugin-search-plus/jquery.mark.min.js"></script>
<script src="../gitbook/gitbook-plugin-search-plus/search.js"></script>
<script src="../gitbook/gitbook-plugin-lightbox/js/lightbox.min.js"></script>
<script src="../gitbook/gitbook-plugin-change_girls/girls.js"></script>
<script src="../gitbook/gitbook-plugin-pageview-count/plugin.js"></script>
<script src="../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
<script src="../gitbook/gitbook-plugin-theme-comscore/test.js"></script>
<script src="../gitbook/gitbook-plugin-mermaid-gb3/mermaid/mermaid.min.js"></script>
</body>
</html>
