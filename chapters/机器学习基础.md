![异世界.png](./res/other/异世界蕾姆_1.png)

[TOC]

# 机器学习基础

> [机器学习必备的数学基础有哪些？](https://36kr.com/p/5124507)
>
> [机器学习几种方式](https://www.cnblogs.com/huicpc0212/p/4192214.html)
>
> [大规模机器学习框架的四重境界](https://www.leiphone.com/news/201711/89T9wKWOxwCTCSHZ.html)
>
> [参数服务器——分布式机器学习的新杀器](https://blog.csdn.net/u010945683/article/details/78717064)
>
> [腾讯首个 AI 开源项目 Angel 发布 3.0 版本：迈向全栈机器学习平台](https://www.oschina.net/news/109299/angel-3-0-0-released)
>
> [Factorization Machines(FM) 因子分解机和Field-aware Factorization Machine (FFM) 场感知分解机](https://blog.csdn.net/asd136912/article/details/78318563)
>
> [FM算法解析](https://zhuanlan.zhihu.com/p/37963267)
>
> [因子分解机（FM）与场感知分解机（FFM）](https://plushunter.github.io/2017/07/13/机器学习算法系列（26）：因子分解机（FM）与场感知分解机（FFM）/)
>
> https://keysaim.github.io/post/blog/2017-08-15-how-to-setup-your-github-io-blog/
>
> [腾讯发布开源机器学习平台 Angel 3.0](https://www.infoq.cn/article/1oFNtcMgWPGPLi1iA4ma)

>* 《分布式机器学习：算法、理论与实践》刘铁岩等著
>* 从`学习目标`的角度，机器学习可以大体分成回归、分类、排序、有结构预测等类别。这些类别的主要差别在于机器学习模型输出的格式，以及如何衡量输出的准确程度。
>  * 在`回归`问题里，模型的输出值一般是一个连续的标量，人们通常用模型输出与真值之间的最小平方误差来衡量模型的准确程度。
>  * 在`分类`问题里，模型的输出是一个或多个类别标签，人们通常使用0-1误差及其损失函数(如交叉嫡、Hinge函数、指数函数等)来衡量模型的准确程度。
>  * 在`排序`问题里，模型的输出是一个经过排序的对象列表，人们通常用序对级别(pairwise)或列表级别(listwise)的损失函数来衡量模型的准确程度。
> * 在更加通用的有`结构预测`问题中，则需要具体问题具体分析，利用领域知识定义合适的输出格式和模型准确程度的判别准则。
>* 从训练`数据特性`的角度，机器学习可以大体分为有监督学习、半监督学习、无监督学习、弱监督学习等类别。
> * `有监督学习`，指的是每个训练数据都拥有标签。这样一来，在每个训练样本上都可以精准地计算损失，并且根据损失对模型进行优化。
>  * `半监督学习`指的是训练集里同时存在有标签数据和无标签数据。通常人们需要对无标签数据进行一些预处理(比如根据它们和有标签数据的相似性来预测其伪标签，或者计算它们彼此之间的相似性以获取对整个数据集分布的先验知识)，然后利用它们来协助原有的训练过程(比如把伪标签当作真实标签使用，或把数据集分布作为正则项来增强模型的泛化能力)。
>  * `无监督学习`处理的数据全都是无标签的。学习的目的是从数据中发掘关联规则，或者利用数据在输入空间中的相互关系(如相似性、距离、偏序关系等)对数据进行聚类和影响力排序。
>  * `弱监督学习`中存在某种形式的奖励信号，该信号可以用于模型训练，但是没有样本标签那么直接、完全、确切或者准确。强化学习是一类典型的弱监督学习问题，它无须依赖预先给定的离线训练数据，而是通过与环境的试探性交互来进行学习。具体而言，学习机制通过选择并执行某些动作，导致环境状态变化，并得到来自环境的奖励信号。学习的目标是寻找一个合适的动作选择策略，使产生的动作序列获得最优的累计奖励。
>
>*  从`模型复杂程度`的角度，机器学习可以分为线性模型与非线性模型(或浅层模型与深层模型)。
> 
>  * `线性模型`包括线性回归、逻辑回归、线性支持向量机等。这些模型可以通过核化进行非线性变换，从而获得更加强大的表达能力。
>* `非线性模型`包括决策树、深层神经网络(包括全连接神经网络、卷积神经网络、循环神经网络等)。它们具有很强的表达能力，可以更好地拟合训练数据。
> *  从`模型的功能`角度，机器学习可以划分为生成模型和判别模型。
>* `生成模型`在学习过程中通常以最大化训练数据的似然为目的，关注的是输入样本和标签的联合概率分布。生成模型要学习的概率分布比较复杂，但适用场合很丰富，既可以用来完成分类任务，也可以实现概率密度估计或样本的随机生成。
>* `判别模型`通常最大化的是条件似然，也就是关注在给定输入样本的前提下标签的条件概率。判别模型单刀直入，解决的是一个判别问题，不需要对联合分布做不必要的刻画，学习效率比较高，但适用场景也因此受到一定程度的限制。
> 
>    

> **1、有监督学习**：通过已有的训练样本去训练得到一个最优模型，再利用这个模型将所有的输入映射为相应的输出，对输出进行简单的判断从而实现预测和分类的目的，也就具有了对未知数据进行预测和分类的能力。就如有标准答案的练习题，然后再去考试，相比没有答案的练习题然后去考试准确率更高。又如我们小的时候不知道牛和鸟是否属于一类，但当我们随着长大各种知识不断输入，我们脑中的模型越来越准确，判断动物也越来越准确。
>
> 有监督学习可分为***回归和分类***。
>
> **回归：**即给出一堆自变量$$X$$和因变量$$Y$$，拟合出一个函数，这些自变量$$X$$就是特征向量，因变量$$Y$$就是标签。 而且标签的值**连续**的，例LR。
>
> **分类**：其数据集，由特征向量$$X$$和它们的标签$$Y$$组成，当你利用数据训练出模型后，给你一个只知道特征向量不知道标签的数据，让你求它的标签是哪一个？其输出结果是**离散**的。例如logistics、SVM、KNN等。
>
> **2、无监督学习：**我们事先没有任何训练样本，而需要直接对数据进行建模。比如我们去参观一个画展，我们完全对艺术一无所知，但是欣赏完多幅作品之后，我们也能把它们分成不同的派别。无监督学习主要算法是聚类，聚类目的在于把相似的东西聚在一起，主要通过计算样本间和群体间距离得到，主要算法包括Kmeans、层次聚类、EM算法。





